{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b74ef69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Created 84 RAG-ready chunks.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open(\"htsdata.json\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "chunks = []\n",
    "parent_stack = []\n",
    "\n",
    "for item in data:\n",
    "    htsno = item.get(\"htsno\", \"\").strip()\n",
    "    desc = item.get(\"description\", \"\").strip()\n",
    "    indent = int(item.get(\"indent\", 0))\n",
    "\n",
    "    if not desc or desc.lower() == \"other\":\n",
    "        continue\n",
    "\n",
    "    # Maintain hierarchy stack\n",
    "    while len(parent_stack) > indent:\n",
    "        parent_stack.pop()\n",
    "\n",
    "    parent_stack = parent_stack[:indent]\n",
    "    parent_stack.append(desc)\n",
    "\n",
    "    # Skip chunks without htsno (they're just category headers)\n",
    "    if not htsno:\n",
    "        continue\n",
    "\n",
    "    # Create combined text\n",
    "    full_desc = \" → \".join(parent_stack)\n",
    "    chunk = f\"HTS Code: {htsno}\\nDescription: {full_desc}\"\n",
    "    chunks.append(chunk)\n",
    "\n",
    "# Save as a JSON list of chunks\n",
    "with open(\"rag_hts_chunks.json\", \"w\") as f:\n",
    "    json.dump(chunks, f, indent=2)\n",
    "\n",
    "print(f\"✅ Created {len(chunks)} RAG-ready chunks.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "456f67a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Processed 24520 total chunks from all files.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "data_folder = \"Data\"\n",
    "chunks = []\n",
    "\n",
    "# Loop through all files in the folder\n",
    "for filename in os.listdir(data_folder):\n",
    "    if filename.startswith(\"htsdata\") and filename.endswith(\".json\"):\n",
    "        file_path = os.path.join(data_folder, filename)\n",
    "        \n",
    "        with open(file_path) as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        parent_stack = []\n",
    "\n",
    "        for item in data:\n",
    "            htsno = item.get(\"htsno\", \"\").strip()\n",
    "            desc = item.get(\"description\", \"\").strip()\n",
    "            indent = int(item.get(\"indent\", 0))\n",
    "\n",
    "            if not desc or desc.lower() == \"other\":\n",
    "                continue\n",
    "\n",
    "            # Maintain hierarchy stack\n",
    "            while len(parent_stack) > indent:\n",
    "                parent_stack.pop()\n",
    "\n",
    "            parent_stack = parent_stack[:indent]\n",
    "            parent_stack.append(desc)\n",
    "\n",
    "            # Skip chunks without htsno\n",
    "            if not htsno:\n",
    "                continue\n",
    "\n",
    "            # Combine parent + current\n",
    "            full_desc = \" → \".join(parent_stack)\n",
    "            chunk = f\"HTS Code: {htsno}\\nDescription: {full_desc}\"\n",
    "            chunks.append(chunk)\n",
    "\n",
    "print(f\"✅ Processed {len(chunks)} total chunks from all files.\")\n",
    "\n",
    "# Save combined output\n",
    "with open(\"rag_hts_chunks_all.json\", \"w\") as f:\n",
    "    json.dump(chunks, f, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d18a576c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Cleaned 24520 entries saved to 'cleaned_rag_hts_data.json'\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "# Load your previously processed file\n",
    "with open(\"rag_hts_chunks_all.json\", \"r\") as f:\n",
    "    chunks = json.load(f)\n",
    "\n",
    "cleaned_chunks = []\n",
    "\n",
    "for entry in chunks:\n",
    "    if not entry.startswith(\"HTS Code:\"):\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        hts_line, desc_line = entry.split(\"\\n\", 1)\n",
    "        hts_code = hts_line.replace(\"HTS Code:\", \"\").strip()\n",
    "        description = desc_line.replace(\"Description:\", \"\").strip()\n",
    "\n",
    "        # Replace Unicode arrows or other symbols with commas\n",
    "        clean_desc = re.sub(r\"[\\u2192:]+\", \",\", description)\n",
    "        clean_desc = re.sub(r\"\\s*,\\s*\", \", \", clean_desc)  # normalize comma spacing\n",
    "        clean_desc = re.sub(r\"\\s{2,}\", \" \", clean_desc)    # collapse extra spaces\n",
    "        clean_desc = clean_desc.strip(\", \").capitalize()\n",
    "\n",
    "        cleaned_chunks.append({\n",
    "            \"hts_code\": hts_code,\n",
    "            \"description\": clean_desc\n",
    "        })\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Skipping malformed entry: {entry[:50]}...\")\n",
    "\n",
    "# Save cleaned result\n",
    "with open(\"cleaned_rag_hts_data.json\", \"w\") as f:\n",
    "    json.dump(cleaned_chunks, f, indent=2)\n",
    "\n",
    "print(f\"✅ Cleaned {len(cleaned_chunks)} entries saved to 'cleaned_rag_hts_data.json'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e13b8240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Final cleaned 24520 entries saved to 'final_rag_hts_data.json'\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "# Load your semi-cleaned file\n",
    "with open(\"cleaned_rag_hts_data.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "final_data = []\n",
    "\n",
    "for entry in data:\n",
    "    hts = entry[\"hts_code\"]\n",
    "    desc = entry[\"description\"]\n",
    "\n",
    "    # Remove duplicate commas and spaces\n",
    "    desc = re.sub(r\",\\s*,\", \",\", desc)           # Fix \", ,\"\n",
    "    desc = re.sub(r\"\\s+\", \" \", desc)             # Collapse multiple spaces\n",
    "    desc = re.sub(r\"\\s*,\\s*\", \", \", desc)        # Normalize comma spacing\n",
    "    desc = desc.strip(\" ,\")\n",
    "\n",
    "    # Optional: lowercase everything for uniformity\n",
    "    desc = desc.lower()\n",
    "\n",
    "    final_data.append({\n",
    "        \"hts_code\": hts,\n",
    "        \"description\": desc\n",
    "    })\n",
    "\n",
    "# Save final version\n",
    "with open(\"final_rag_hts_data.json\", \"w\") as f:\n",
    "    json.dump(final_data, f, indent=2)\n",
    "\n",
    "print(f\"✅ Final cleaned {len(final_data)} entries saved to 'final_rag_hts_data.json'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85410122",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
